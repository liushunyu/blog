---
layout:     post
title:      "强化学习思考（2）强化学习简介"
subtitle:    "强化学习简介"
date:       2020-04-12 10:00:00
author:     Shunyu
header-img: img/post-bg-2015.jpg
header-mask: 0.1
catalog: true
mathjax: true
tags:
    - 强化学习
    - 强化学习思考
---



关于强化学习简介的注意事项。



## 目录

- [强化学习思考（1）前言](https://liushunyu.github.io/2020/04/12/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%80%9D%E8%80%83-1-%E5%89%8D%E8%A8%80/)
- [强化学习思考（2）强化学习简介](https://liushunyu.github.io/2020/04/12/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%80%9D%E8%80%83-2-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/)
- [强化学习思考（3）马尔可夫决策过程](https://liushunyu.github.io/2020/04/12/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%80%9D%E8%80%83-3-%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/)



## Reward Hypothesis

Reward 是强化学习的核心，强化学习问题中可以没有 state / observation，但是不能没有 reward。（如多臂赌博机问题）

>Definition (Reward Hypothesis):
>
>All goals can be described by the maximisation of expected cumulative reward.

如果一个问题不满足奖励假设，那么就不能用强化学习去解决。



## Model and Environment

Model 会预测 environment 接下来的输出，其定义如下：
$$
\begin{aligned}
P_{ss'}^a &= P[S_{t+1} = s' | S_t = s, A_t = a] \\
R_{s}^a &=E[R_{t+1} | S_t = s, A_t = a]
\end{aligned}
$$



## 强化学习分类

基于不同的分类

### Model Free / Model Based

Model Free 和 Model Based 的最大区别在于 environment 的 model 对于 agent 来说是不是已知的。



### Prediction / Control

强化学习算法通常分为 Prediction 和 Control 两种

> Prediction: evaluate the future with a given policy.
>
> Control: Find the best policy to optimise the future.



### Learning / Planning

- Reinforcement Learning:
  - The environment is initially unknown
  - The agent interacts with the environment
  - The agent improves its policy

- Planning:
  - A model of the environment is known
  - The agent performs computations with its model (without any external interaction)
  - The agent improves its policy
  - a.k.a. deliberation, reasoning, introspection, pondering, thought, search



### Exploration / Exploitation

- Exploration finds more information about the environment
- Exploitation exploits known information to maximise reward



### Value Based / Policy Based

Value Based 和 Policy Based 在于用于决策（选择 action）的函数是 value function 还是 policy function。



### Off-Policy / On-Policy

Off-Policy 学习的 agent 以及和环境进行互动的 agent 是**不同的agent**。 On-Policy 学习的 agent 以及和环境进行互动的 agent 是**相同的agent**。




## 参考资料及致谢

所有参考资料在前言中已列出，再次向强化学习的大佬前辈们表达衷心的感谢！
