---
layout:     post
title:      "pytorch 小技巧"
subtitle:    "pytorch 小技巧"
date:       2020-04-05 09:00:00
author:     Shunyu
header-img: img/post-bg-2015.jpg
header-mask: 0.1
catalog: true
tags:
    - python
    - pytorch
    - tensorboard
---



记录一些写 pytorch 时候不会的点。

**nn.Module 类定义时不要把网络模型放到某些数据结构中（如 list），否则 .to(device) 找不到网络模型，可以使用 nn.ModuleList()**



## GPU 使用

指定 GPU

```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'  # 注意修改环境变量后 device index 可能会发生变化

use_cuda = True
device = torch.device('cuda:{}'.format(args.gpu) if (torch.cuda.is_available() and use_cuda) else 'cpu')
```



查看 GPU 是否可用

```python
import torch
torch.cuda.is_available()
```



使用 cuda

```python
use_cuda = True
device = torch.device('cuda' if (torch.cuda.is_available() and use_cuda) else 'cpu')
```



## 保存提取

```python
# 保存整个网络（网络大的时候可能会比较慢）
torch.save(net, 'net.pkl')  
net = torch.load('net.pkl', map_location=device)

# 只保存网络中的参数（速度快, 占内存少）
torch.save(net.state_dict(), 'net_params.pkl')   
net.load_state_dict(torch.load('net_params.pkl'))
```



## tensorboard 使用

安装 tensorboard

```bash
pip install tensorboard
```



记录 tensorboard

```python
from torch.utils.tensorboard import SummaryWriter

# create a summary writer with automatically generated folder name.
writer = SummaryWriter()
# folder location: runs/May04_22-14-54_s-MacBook-Pro.local/

# create a summary writer using the specified folder name.
writer = SummaryWriter(log_dir="runs/experiment")
# folder location: runs/experiment/

# create a summary writer with comment appended.
writer = SummaryWriter(comment="-LR_0.1_BATCH_16")
# folder location: runs/May04_22-14-54_s-MacBook-Pro.local-LR_0.1_BATCH_16/

# scalar
writer.add_scalar(tag, scalar_value, global_step=***)
writer.add_scalars(main_tag, tag_scalar_dict, global_step=***)

# image
# img_tensor: Default is (3, H, W)
writer.add_image(tag, img_tensor, global_step=None, dataformats='CHW')
# img_tensor: Default is (N, 3, H, W)
writer.add_images(tag, img_tensor, global_step=None, dataformats='NCHW')

# graph
writer.add_graph(model, input_to_model=None)

# figure
writer.add_figure(tag, figure, global_step=None)

# close writer
writer.close()
```



查看 tensorboard

```
tensorboard --logdir=runs --host=0.0.0.0 --port=8025
```



## torchsummary

安装 torchsummary

``` bash
pip install torchsummary
```



使用 torchsummary

``` python
from torchsummary import summary
summary(model, input_size, batch_size=-1, device=torch.device('cuda:0'))
```



## tensor 与 numpy 互转

注意：

- `numpy()`、`from_numpy()` 和 `torch.as_tensor()` 函数得到的数组共享相同的内存（所以他们之间的转换很快）。
- `torch.tensor()` 函数总是会进行数据拷贝（就会消耗更多的时间和空间），所以返回的数组和原来的数据不再共享内存。

```python
# tensor 转 numpy
a.detach().cpu().numpy()

# numpy 转 tensor
b = torch.from_numpy(a)		# 共享内存

# numpy / list 转 tensor
b = torch.tensor(a)				# 不共享内存
b = torch.as_tensor(a)		# 共享内存
```



## 计算内存消耗

int 64，一个int 64中有64位bit，一个字节Byte中有8位bit，所以一个int 64就是8字节。

float32 有32位

print(a.nbytes) 

print(sys.getsizeof(a))

https://blog.csdn.net/weixin_44915226/article/details/104271027



## 参考资料及致谢

[莫烦PYTHON](https://morvanzhou.github.io/)

[PyTorch](https://pytorch.org/)

[pytorch-summary](https://github.com/sksq96/pytorch-summary)

[《动手学深度学习》](http://zh.d2l.ai/) 

[深度学习PyTorch，TensorFlow中GPU利用率较低，CPU利用率很低，且模型训练速度很慢的问题总结与分析](https://blog.csdn.net/qq_32998593/article/details/92849585/)

[Pytorch张量的主要方法之间的区别（Tensor、tensor、from_numpy、as_tensor）](https://blog.csdn.net/qq_41251963/article/details/108362239)